{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "seq2seq_t5_small_fp16.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('usr')",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c257bf9a31a04211b84de8972204121c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f3885690d1ad4061b5da863d6638b895",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d34654fbb62c46b8ab0d3d200d00d671",
              "IPY_MODEL_a2599a5276ef4d00a5a57bff9d47779f",
              "IPY_MODEL_b3389de667ef4c43b1137d138a436c9a"
            ]
          }
        },
        "f3885690d1ad4061b5da863d6638b895": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d34654fbb62c46b8ab0d3d200d00d671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_81228addbf9340cc83fc3f1ae87ff9b2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0da234a6fb6e4a739f748cccffb06a66"
          }
        },
        "a2599a5276ef4d00a5a57bff9d47779f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5993b8f6d9e745248930f73db0d10bad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0feafffaf6024eabb549d9abd8a7e817"
          }
        },
        "b3389de667ef4c43b1137d138a436c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a0aa8bcfdec14dfdaf86896c79f81400",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:01&lt;00:00,  1.41it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6578e6f19978431db47ec33c8a5f181f"
          }
        },
        "81228addbf9340cc83fc3f1ae87ff9b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0da234a6fb6e4a739f748cccffb06a66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5993b8f6d9e745248930f73db0d10bad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0feafffaf6024eabb549d9abd8a7e817": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0aa8bcfdec14dfdaf86896c79f81400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6578e6f19978431db47ec33c8a5f181f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba841c3adaf842419d8092125cd27556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8e44814768ec4201b583625f05fd805a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ff4958e1bcca49b9a690390315557bb2",
              "IPY_MODEL_e3306404aedc43338f7c7caabd310081",
              "IPY_MODEL_9255c31f208d471f842a29e1ac69b2a1"
            ]
          }
        },
        "8e44814768ec4201b583625f05fd805a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff4958e1bcca49b9a690390315557bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aa0b7f48033345e286d1e97afeb41e3a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_464270ca2d33471a969b1df4060d0b7a"
          }
        },
        "e3306404aedc43338f7c7caabd310081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_faf1a7ba27df45b6a8c619794a617d43",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 39,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 39,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4111da1ac25a46078fe7990156b208f5"
          }
        },
        "9255c31f208d471f842a29e1ac69b2a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bea3582ab69a42ae9581eebb00d30a43",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 39/39 [00:07&lt;00:00,  4.79ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d694019cd9f40539cd0cb2342f9b523"
          }
        },
        "aa0b7f48033345e286d1e97afeb41e3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "464270ca2d33471a969b1df4060d0b7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "faf1a7ba27df45b6a8c619794a617d43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4111da1ac25a46078fe7990156b208f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bea3582ab69a42ae9581eebb00d30a43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d694019cd9f40539cd0cb2342f9b523": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTZYaL1ANwxu"
      },
      "source": [
        "# Following https://github.com/huggingface/notebooks/blob/master/examples/translation.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "566GHCfaILnG",
        "outputId": "70a7dda1-27f5-4e6b-c4a4-ca6fd41a804f"
      },
      "source": [
        "!pip install wandb datasets transformers sacrebleu==1.5.1 -qqq"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 270 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 37.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 46.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 125 kB 39.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 243 kB 48.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 37.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 636 kB 45.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 35.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 45.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 160 kB 43.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYAJwVTidmMe",
        "outputId": "99114328-5dde-44fc-f5e0-aa53c5497d53"
      },
      "source": [
        "!pip install bert-score -qqq"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█████▌                          | 10 kB 23.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 20 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 30 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 40 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 51 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 59 kB 3.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpHoG6l5Nx1E",
        "outputId": "9dbfe9d5-0288-4f3a-dcea-2f99a4405abb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXgnU7gQOGGS",
        "outputId": "185674a9-e9b2-44fe-88c9-6b7b35f5f920"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Oct 11 13:02:37 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   71C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9TjriZbNwxy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "608eea8e-9f55-45c2-b7f4-22c86a3d6ad0"
      },
      "source": [
        "import datetime\n",
        "model_checkpoint = 't5-small'\n",
        "fp16 = True\n",
        "todaydate = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "print(todaydate)\n",
        "gdir = f'drive/My Drive/Colab Notebooks/{todaydate}/'\n",
        "model_name=f'sparql-translator-{todaydate}-{model_checkpoint}' + '-fp16' if fp16 else ''\n",
        "model_path='./models/'+model_name\n",
        "ds_path= 'lc-quad-wikidata-2021-10-11'\n",
        "ds_name = 'yazdipour/text-to-sparql-t5-lc-quad-v2'"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUM2HkRlKpUE",
        "outputId": "4d0b7f63-e9c2-4197-a5dd-369c564afb15"
      },
      "source": [
        "!unzip {ds_path}.zip"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  lc-quad-wikidata-2021-10-11.zip\n",
            " extracting: lc-quad-wikidata-2021-10-11/dataset_dict.json  \n",
            "   creating: lc-quad-wikidata-2021-10-11/test/\n",
            "  inflating: lc-quad-wikidata-2021-10-11/test/dataset.arrow  \n",
            "  inflating: lc-quad-wikidata-2021-10-11/test/dataset_info.json  \n",
            "  inflating: lc-quad-wikidata-2021-10-11/test/state.json  \n",
            "   creating: lc-quad-wikidata-2021-10-11/train/\n",
            "  inflating: lc-quad-wikidata-2021-10-11/train/dataset.arrow  \n",
            "  inflating: lc-quad-wikidata-2021-10-11/train/dataset_info.json  \n",
            "  inflating: lc-quad-wikidata-2021-10-11/train/state.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "ueKQ2exH7rX-",
        "outputId": "f00a76c7-3269-4a53-a8ba-f4b9ac99a4e8"
      },
      "source": [
        "# Flexible integration for any Python script\n",
        "import wandb\n",
        "\n",
        "# 1. Start a W&B run\n",
        "wandb.init(project='text-to-sparql', entity='shahriar', name= f'{todaydate}-{model_checkpoint}')\n",
        "\n",
        "# 2. Save model inputs and hyperparameters\n",
        "config = wandb.config\n",
        "config.learning_rate = 0.01"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/shahriar/text-to-sparql/runs/2cqudtih\" target=\"_blank\">2021-10-11-t5-small</a></strong> to <a href=\"https://wandb.ai/shahriar/text-to-sparql\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Wpgv7Jit9qN5",
        "outputId": "9d9084c7-238b-47f1-87bc-407e7c90a97d"
      },
      "source": [
        "model_name"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sparql-translator-2021-10-11-t5-small-fp16'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Acx8YqC8Ok-H"
      },
      "source": [
        "!mkdir models"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0gq9_ijtbHt"
      },
      "source": [
        "from datasets import load_dataset, load_metric, Dataset, load_from_disk"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGFsMmwlNwxz"
      },
      "source": [
        "raw_datasets = load_from_disk(ds_path)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2iDM_pKTyP3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247,
          "referenced_widgets": [
            "c257bf9a31a04211b84de8972204121c",
            "f3885690d1ad4061b5da863d6638b895",
            "d34654fbb62c46b8ab0d3d200d00d671",
            "a2599a5276ef4d00a5a57bff9d47779f",
            "b3389de667ef4c43b1137d138a436c9a",
            "81228addbf9340cc83fc3f1ae87ff9b2",
            "0da234a6fb6e4a739f748cccffb06a66",
            "5993b8f6d9e745248930f73db0d10bad",
            "0feafffaf6024eabb549d9abd8a7e817",
            "a0aa8bcfdec14dfdaf86896c79f81400",
            "6578e6f19978431db47ec33c8a5f181f"
          ]
        },
        "outputId": "5e9cb9a8-5560-4d43-f956-fd1388a72e6a"
      },
      "source": [
        "# raw_datasets = load_dataset(\"yazdipour/text-to-sparql-t5-lc-quad-v2\", data_files={\"train\": \"train.csv\", \"test\": \"test.csv\"})"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration text-to-sparql-t5-lc-quad-v2-bb37c48c93c1fd45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset csv/text-to-sparql-t5-lc-quad-v2 to /root/.cache/huggingface/datasets/csv/text-to-sparql-t5-lc-quad-v2-bb37c48c93c1fd45/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c257bf9a31a04211b84de8972204121c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3ab09cb49e54392aa1d901c6bd69e62",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/8.65M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "adf9cb37bfcf48d0850e11657b6458ce",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.17M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59752cb9dd68427391a6d8c0bbd6646c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94a481e1a95543f2be469d8b0376e204",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0 tables [00:00, ? tables/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "904839aa77d84c1487e4d877426055b3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0 tables [00:00, ? tables/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/text-to-sparql-t5-lc-quad-v2-bb37c48c93c1fd45/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3f59e3a212b414ab699f02581fdfea4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak3Fc0pDUG8_"
      },
      "source": [
        "# !pip install tqdm==4.49.0"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dRUZHjeNwxz"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGDdBpGfNwxz"
      },
      "source": [
        "# Preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "id": "UnY4aKkPNwx0",
        "outputId": "4e4fc2b7-c115-444d-95ad-561942fe6e70"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be4ba4b21fa54c0a8b31cb6975734f6d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b4d59fb1bd04416951774a32d6a3eb5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9207fef08db64bcdb9cbb3c6aaf3387e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.32M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZdjRilTNwx1",
        "outputId": "c6f3042f-81c9-4de2-bb36-9c8f7e728ae2"
      },
      "source": [
        "print(raw_datasets['test']['translation'][0]['sparql'],'\\n',\n",
        "      raw_datasets['test']['translation'][0]['en'],'\\n',\n",
        "      tokenizer(raw_datasets['test']['translation'][0]['en']))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "select ?answer where [ wd:nico_yennaris wdt:member_of_sports_team ?X . ?X wdt:color ?answer] \n",
            " who colors of player of nico yennaris ? \n",
            " {'input_ids': [113, 2602, 13, 1959, 13, 3, 2532, 32, 3, 63, 35, 29, 1665, 7, 3, 58, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkidcZ_hNwx2",
        "outputId": "3504266d-fdd4-4cbc-e9da-dfe3af6b278c"
      },
      "source": [
        "max_input_length = 0 \n",
        "max_target_length = 0\n",
        "for d in tqdm(raw_datasets['train']['translation']):\n",
        "    len_en = len(d['en'])\n",
        "    len_qry = len(d['sparql'])\n",
        "    if len_en > max_input_length: max_input_length=len_en\n",
        "    if len_qry > max_target_length: max_target_length=len_qry\n",
        "print('\\n',max_input_length, max_target_length)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38448/38448 [00:00<00:00, 1111174.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " 248 323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXiURhR-Nwx3"
      },
      "source": [
        "source_lang = \"en\"\n",
        "target_lang = \"sparql\"\n",
        "prefix = \"translate english to sparql: \"\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = []\n",
        "    targets= []\n",
        "    for ex in examples[\"translation\"]:\n",
        "      inputs.append(prefix + ex[source_lang])\n",
        "      targets.append(ex[target_lang])\n",
        "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
        "\n",
        "    # Setup the tokenizer for targets\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "      labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
        "      \n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "ba841c3adaf842419d8092125cd27556",
            "8e44814768ec4201b583625f05fd805a",
            "ff4958e1bcca49b9a690390315557bb2",
            "e3306404aedc43338f7c7caabd310081",
            "9255c31f208d471f842a29e1ac69b2a1",
            "aa0b7f48033345e286d1e97afeb41e3a",
            "464270ca2d33471a969b1df4060d0b7a",
            "faf1a7ba27df45b6a8c619794a617d43",
            "4111da1ac25a46078fe7990156b208f5",
            "bea3582ab69a42ae9581eebb00d30a43",
            "2d694019cd9f40539cd0cb2342f9b523"
          ]
        },
        "id": "qmaK1UX0Nwx3",
        "outputId": "66cf5481-94df-4cf9-b537-6b434e318482"
      },
      "source": [
        "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba841c3adaf842419d8092125cd27556",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/39 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2042e076acc14af9b2c1fc2d6bfce914",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knRoh_8wNwx4",
        "outputId": "adacc9e1-5c81-4598-d3d5-df7986aefe0b"
      },
      "source": [
        "tokenized_datasets"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['__index_level_0__', 'attention_mask', 'input_ids', 'labels', 'translation'],\n",
              "        num_rows: 38448\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['__index_level_0__', 'attention_mask', 'input_ids', 'labels', 'translation'],\n",
              "        num_rows: 9612\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUiaZ1Y0Nwx4"
      },
      "source": [
        "# Fine-tuning the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "rUJNfPjvNwx5",
        "outputId": "bf5c983b-30f4-4c52-b4f0-627d04b1333e"
      },
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1164213cc15b4c209a0fa1eeb00f809f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/231M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt8rECNwNwx5"
      },
      "source": [
        "batch_size = 16\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    model_name,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=1,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        ")"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHZPXO3lNwx5"
      },
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E_b1Wc4gbMf"
      },
      "source": [
        "import numpy as np\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.replace('?',' ?').replace('.', ' .').strip() for pred in preds]\n",
        "    labels = [[label.replace('?',' ?').replace('.', ' .').strip()] for label in labels]\n",
        "    return preds, labels"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQyXIlPMgqzO"
      },
      "source": [
        "# The last thing to define for our Seq2SeqTrainer is how to compute \n",
        "# the metrics from the predictions. We need to define \n",
        "# a function for this, which will just use the metric we loaded earlier, \n",
        "# and we have to do a bit of pre-processing to decode the predictions into texts:"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6e8FOhSBjZKM",
        "outputId": "60d2c5dd-e756-4fbf-bf16-ba61154bb142"
      },
      "source": [
        "from bert_score import BERTScorer\n",
        "scorer = BERTScorer(lang=\"en\", rescale_with_baseline=True)\n",
        "metric = load_metric(\"sacrebleu\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.11.3\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/roberta-large/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/7c1ba2435b05451bc3b4da073c8dec9630b22024a65f6c41053caccf2880eb8f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
            "loading file https://huggingface.co/roberta-large/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/20b5a00a80e27ae9accbe25672aba42ad2d4d4cb2c4b9359b50ca8e34e107d6d.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/roberta-large/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/roberta-large/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/roberta-large/resolve/main/tokenizer_config.json from cache at None\n",
            "loading file https://huggingface.co/roberta-large/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/e16a2590deb9e6d73711d6e05bf27d832fa8c1162d807222e043ca650a556964.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
            "loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.11.3\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.11.3\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/roberta-large/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/8e36ec2f5052bec1e79e139b84c2c3089cb647694ba0f4f634fec7b8258f7c89.c43841d8c5cd23c435408295164cda9525270aa42cd0cc9200911570c0342352\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of RobertaModel were initialized from the model checkpoint at roberta-large.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce7d355f3e7c42fda4a9de93d6e381c4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.37k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxB0Sih5fsYd"
      },
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    P, R, F1 = scorer.score(decoded_preds, decoded_labels)\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    \n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "    gen_len = np.mean(prediction_lens)\n",
        "    \n",
        "    return {\"gen_len\":gen_len, 'P':P.mean(), 'R':R.mean(), 'F1':F1.mean(), \"bleu-score\": result[\"score\"], \"bleu-precisions\": result[\"precisions\"], \"bleu-bp\": result[\"bp\"]}"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TzcEj3jKSlD"
      },
      "source": [
        "# metric = load_metric(\"sacrebleu\")\n",
        "\n",
        "# def compute_metrics(eval_preds):\n",
        "#     preds, labels = eval_preds\n",
        "#     if isinstance(preds, tuple):\n",
        "#         preds = preds[0]\n",
        "#     decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "#     # Replace -100 in the labels as we can't decode them.\n",
        "#     labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "#     decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "#     # Some simple post-processing\n",
        "#     decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "#     result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "#     # result = {\"bleu\": result[\"score\"]}\n",
        "\n",
        "#     prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "#     result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "#     # result = {k: round(v, 4) for k, v in result.items()}\n",
        "#     return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZhWPx09Nwx6",
        "outputId": "1b356735-a121-4fe7-d451-9510634f2b18"
      },
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using amp fp16 backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "id": "qS5Q9hT2Nwx6",
        "outputId": "9f3cf0f0-95ab-49e2-d653-214b7d236d3f"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation, __index_level_0__.\n",
            "***** Running training *****\n",
            "  Num examples = 38448\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2403\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2403' max='2403' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2403/2403 49:57, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Gen Len</th>\n",
              "      <th>P</th>\n",
              "      <th>R</th>\n",
              "      <th>F1</th>\n",
              "      <th>Bleu-score</th>\n",
              "      <th>Bleu-precisions</th>\n",
              "      <th>Bleu-bp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.854400</td>\n",
              "      <td>0.600161</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>0.502704</td>\n",
              "      <td>0.059806</td>\n",
              "      <td>0.272079</td>\n",
              "      <td>4.219543</td>\n",
              "      <td>[83.34756782173942, 63.94946878799091, 50.8666439170187, 43.14391476827958]</td>\n",
              "      <td>0.072151</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to sparql-translator-2021-10-11-t5-small-fp16/checkpoint-500\n",
            "Configuration saved in sparql-translator-2021-10-11-t5-small-fp16/checkpoint-500/config.json\n",
            "Model weights saved in sparql-translator-2021-10-11-t5-small-fp16/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in sparql-translator-2021-10-11-t5-small-fp16/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in sparql-translator-2021-10-11-t5-small-fp16/checkpoint-500/special_tokens_map.json\n",
            "Deleting older checkpoint [sparql-translator-2021-10-11-t5-small-fp16/checkpoint-1000] due to args.save_total_limit\n",
            "Saving model checkpoint to sparql-translator-2021-10-11-t5-small-fp16/checkpoint-1000\n",
            "Configuration saved in sparql-translator-2021-10-11-t5-small-fp16/checkpoint-1000/config.json\n",
            "Model weights saved in sparql-translator-2021-10-11-t5-small-fp16/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in sparql-translator-2021-10-11-t5-small-fp16/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in sparql-translator-2021-10-11-t5-small-fp16/checkpoint-1000/special_tokens_map.json\n",
            "Deleting older checkpoint [sparql-translator-2021-10-11-t5-small-fp16/checkpoint-1500] due to args.save_total_limit\n",
            "Saving model checkpoint to sparql-translator-2021-10-11-t5-small-fp16/checkpoint-1500\n",
            "Configuration saved in sparql-translator-2021-10-11-t5-small-fp16/checkpoint-1500/config.json\n",
            "Model weights saved in sparql-translator-2021-10-11-t5-small-fp16/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in sparql-translator-2021-10-11-t5-small-fp16/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in sparql-translator-2021-10-11-t5-small-fp16/checkpoint-1500/special_tokens_map.json\n",
            "Deleting older checkpoint [sparql-translator-2021-10-11-t5-small-fp16/checkpoint-2000] due to args.save_total_limit\n",
            "Saving model checkpoint to sparql-translator-2021-10-11-t5-small-fp16/checkpoint-2000\n",
            "Configuration saved in sparql-translator-2021-10-11-t5-small-fp16/checkpoint-2000/config.json\n",
            "Model weights saved in sparql-translator-2021-10-11-t5-small-fp16/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in sparql-translator-2021-10-11-t5-small-fp16/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in sparql-translator-2021-10-11-t5-small-fp16/checkpoint-2000/special_tokens_map.json\n",
            "Deleting older checkpoint [sparql-translator-2021-10-11-t5-small-fp16/checkpoint-500] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: translation, __index_level_0__.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9612\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2404' max='2403' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2403/2403 40:06, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1202' max='601' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [601/601 53:43]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"[83.34756782173942, 63.94946878799091, 50.8666439170187, 43.14391476827958]\" of type <class 'list'> for key \"eval/bleu-precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2403, training_loss=0.8568984280513616, metrics={'train_runtime': 2998.9191, 'train_samples_per_second': 12.821, 'train_steps_per_second': 0.801, 'total_flos': 1813926953091072.0, 'train_loss': 0.8568984280513616, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdHQ-R8XNwx6",
        "outputId": "0076e5b1-3fec-4937-f3b0-17fc0ac8aaaa"
      },
      "source": [
        "trainer.save_model(model_path)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./models/sparql-translator-2021-10-11-t5-small-fp16\n",
            "Configuration saved in ./models/sparql-translator-2021-10-11-t5-small-fp16/config.json\n",
            "Model weights saved in ./models/sparql-translator-2021-10-11-t5-small-fp16/pytorch_model.bin\n",
            "tokenizer config file saved in ./models/sparql-translator-2021-10-11-t5-small-fp16/tokenizer_config.json\n",
            "Special tokens file saved in ./models/sparql-translator-2021-10-11-t5-small-fp16/special_tokens_map.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeNvtqwLfj4H",
        "outputId": "ad99e409-091d-4bed-be55-199fd2627b80"
      },
      "source": [
        "!ls -l --block-size=M {model_path}"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 233M\n",
            "-rw-r--r-- 1 root root   1M Oct 11 15:11 config.json\n",
            "-rw-r--r-- 1 root root 231M Oct 11 15:11 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root   1M Oct 11 15:11 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root   1M Oct 11 15:11 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root   2M Oct 11 15:11 tokenizer.json\n",
            "-rw-r--r-- 1 root root   1M Oct 11 15:11 training_args.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NivCzVmChYft"
      },
      "source": [
        "!mkdir drive/MyDrive/models/{model_name}"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueXkcK7rf5SI"
      },
      "source": [
        "!cp {model_path}/* drive/MyDrive/models/{model_name}/"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "47f08Jsr6kU8",
        "outputId": "1496f150-fb1e-4d42-c669-47fb4220c4fb"
      },
      "source": [
        "[83.34756782173942, 63.94946878799091, 50.8666439170187, 43.14391476827958].mean()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-f674bde77e90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;36m83.34756782173942\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m63.94946878799091\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50.8666439170187\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m43.14391476827958\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'mean'"
          ]
        }
      ]
    }
  ]
}