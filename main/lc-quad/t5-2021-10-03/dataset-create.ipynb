{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "ds_path='../../../data/dataset/lc-quad-wikidata-2021-10-03'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "raw_datasets = load_dataset(\"lc_quad\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset lc_quad (/home/shyaz/.cache/huggingface/datasets/lc_quad/default/2.0.0/139ee1f12aca006669dcc1f282ec02e126c69e7595453db443ab022643d54086)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "raw_datasets[\"train\"][0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'NNQT_question': 'What is the {periodical literature} for {mouthpiece} of {Delta Air Lines}',\n",
       " 'paraphrased_question': \"What is Delta Air Line's periodical literature mouthpiece?\",\n",
       " 'question': 'What periodical literature does Delta Air Lines use as a moutpiece?',\n",
       " 'sparql_dbpedia18': 'select distinct ?obj where { ?statement <http://www.w3.org/1999/02/22-rdf-syntax-ns#subject> <http://wikidata.dbpedia.org/resource/Q188920> . ?statement <http://www.w3.org/1999/02/22-rdf-syntax-ns#predicate> <http://www.wikidata.org/entity/P2813> . ?statement <http://www.w3.org/1999/02/22-rdf-syntax-ns#object> ?obj . ?obj <http://www.wikidata.org/entity/P31> <http://wikidata.dbpedia.org/resource/Q1002697> } ',\n",
       " 'sparql_wikidata': ' select distinct ?obj where { wd:Q188920 wdt:P2813 ?obj . ?obj wdt:P31 wd:Q1002697 } ',\n",
       " 'subgraph': 'simple question right',\n",
       " 'template': ' <S P ?O ; ?O instanceOf Type>',\n",
       " 'template_index': 65,\n",
       " 'uid': 19719}"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "rep_dict = {\"ASK\": \"ask\", \"WHERE\": \"where\", \"SELECT\": \"select\", \"{\": \"[\",\"}\": \"]\", }\n",
    "rep_dict2 = {\"{\": \"\",\"}\": \"\" }\n",
    "def replace_all(text, dict):\n",
    "    for i, j in dict.items(): text = text.replace(i, j)\n",
    "    return text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Goal: Trim + Replace LowerCase + Remove weirdly long Question + replaceQ/P"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "df_q = pd.read_csv('../../../data/kdwd/q_19174151.csv').set_index('item_id')\n",
    "df_p = pd.read_csv('../../../data/kdwd/p_12267.csv').set_index('property_id')\n",
    "\n",
    "from pandasql import sqldf\n",
    "pysqldf = lambda q: sqldf(q, globals())\n",
    "\n",
    "def encode_props(qry):\n",
    "    # Q\n",
    "    for m in re.finditer(\":Q\\d+\", qry):\n",
    "        x = m.group(0)[1:]\n",
    "        newstring = df_q.loc[int(x[1:])]['en_label'].iloc[0].replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "        qry = qry.replace(x, newstring)\n",
    "    # P\n",
    "    for m in re.finditer(\":P\\d+\", qry):\n",
    "        x = m.group(0)[1:]\n",
    "        newstring = df_p.loc[int(x[1:])]['en_label'].iloc[0].replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "        qry = qry.replace(x, newstring)\n",
    "    return qry\n",
    "# Test\n",
    "encode_props('SELECT ?obj WHERE { wd:Q1045 p:P1082 ?s . ?s ps:P1082 ?obj . ?s pq:P585 ?x filter(contains(YEAR(?x),\\'2009\\')) }')\n",
    "# \"select ?obj where [ wd:somalia p:population ?s . ?s ps:population ?obj . ?s pq:point_in_time ?x filter(contains(YEAR(?x),'2009')) ]\""
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"SELECT ?obj WHERE { wd:somalia p:population ?s . ?s ps:population ?obj . ?s pq:point_in_time ?x filter(contains(YEAR(?x),'2009')) }\""
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "encode_props('select ?obj where { wd:Q124057 p:P1411 ?s . ?s ps:P1411 ?obj . ?s pq:P1686 wd:Q3915489 }')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'select ?obj where { wd:dolores_del_río p:nominated_for ?s . ?s ps:nominated_for ?obj . ?s pq:for_work wd:otra }'"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def prepare(ds):\n",
    "    col = 'translation'\n",
    "    df = pd.DataFrame(columns=[col])\n",
    "    for d in tqdm(ds):\n",
    "        try:\n",
    "            qry = replace_all(d['sparql_wikidata'], rep_dict).strip()\n",
    "            qry = encode_props(qry)\n",
    "            if len(d['question'])<250: \n",
    "                df = df.append({col: {'en':d['question'], 'sparql': qry}}, ignore_index=True)\n",
    "            if d['paraphrased_question']!=[] and len(d['paraphrased_question'])<250:\n",
    "                df = df.append({col: {'en':d['paraphrased_question'], 'sparql': qry}}, ignore_index=True)\n",
    "        except: pass\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "df_test = prepare(raw_datasets[\"test\"])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 4781/4781 [02:29<00:00, 32.07it/s]\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "df_train = prepare(raw_datasets[\"train\"])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 19293/19293 [08:36<00:00, 37.36it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "df_all = pd.concat([df_train, df_test])\n",
    "# shuffling all\n",
    "df_all  = df_all.sample(frac = 1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df_all, test_size=0.2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "ds_train = Dataset.from_pandas(df_train)\n",
    "ds_test = Dataset.from_pandas(df_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "pd.options.display.max_colwidth = 100\n",
    "df_test.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>{'en': 'When Alec Guinness was nominated as Academy Award for Best Actor?', 'sparql': 'select ?v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11751</th>\n",
       "      <td>{'en': 'Let me know financial marker whose title has the word soil in it.', 'sparql': 'select DI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'en': 'Tell me the historical period which is part of the time period of Muromachi period and w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>{'en': 'Warren G. Harding, whose electoral district is Ohio, holds what position?', 'sparql': 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13148</th>\n",
       "      <td>{'en': 'Where did Lyudmila Pavlinchenko begin school at in 1937?', 'sparql': 'select ?obj where ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                               translation\n",
       "480    {'en': 'When Alec Guinness was nominated as Academy Award for Best Actor?', 'sparql': 'select ?v...\n",
       "11751  {'en': 'Let me know financial marker whose title has the word soil in it.', 'sparql': 'select DI...\n",
       "10     {'en': 'Tell me the historical period which is part of the time period of Muromachi period and w...\n",
       "1071   {'en': 'Warren G. Harding, whose electoral district is Ohio, holds what position?', 'sparql': 's...\n",
       "13148  {'en': 'Where did Lyudmila Pavlinchenko begin school at in 1937?', 'sparql': 'select ?obj where ..."
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "df_test.iloc[0].translation    "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'en': 'When Alec Guinness was nominated as Academy Award for Best Actor?',\n",
       " 'sparql': 'select ?value where [ wd:alec_guinness p:nominated_for ?s . ?s ps:nominated_for wd:best_actor . ?s pq:point_in_time ?value]'}"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "ds_train"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['translation', '__index_level_0__'],\n",
       "    num_rows: 15123\n",
       "})"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "mother_ds = DatasetDict({'train': ds_train, 'test':ds_test})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "mother_ds.save_to_disk(ds_path)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}