{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10f8a20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72d7ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c64afe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0656defd",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d91c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1157dfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = transformers.T5Config.from_json_file(json_file=\"t5-base-config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7af072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = t5.models.HfPyTorchModel(\"t5-small\", \"/tmp/hft5/\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f682be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/google-research/text-to-text-transfer-transformer/issues/172\n",
    "model1 = t5.models.HfPyTorchModel(transformers.T5Config(), \"/tmp/hft5/\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f313c66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = t5.models.HfPyTorchModel(config, \"/tmp/hft5/\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e6f966",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers.T5Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6df51037",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Available objects for config:\n     AliasManager\n     DisplayFormatter\n     HistoryManager\n     IPCompleter\n     IPKernelApp\n     LoggingMagics\n     MagicsManager\n     OSMagics\n     PrefilterManager\n     ScriptMagics\n     StoreMagics\n     ZMQInteractiveShell\n"
     ]
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50522656",
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "No Task or Mixture found with name: glue_cola_v002",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4209a2806a79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate the pre-trained checkpoint, before further fine-tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model.eval(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"glue_cola_v002\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"targets\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/t5/models/hf_model.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, mixture_or_task_name, sequence_length, batch_size, checkpoint_steps, summary_dir, split, compute_sequence_length, **generate_kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m     run_eval(\n\u001b[0m\u001b[1;32m    447\u001b[0m         \u001b[0mmixture_or_task_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmixture_or_task_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mpredict_or_score_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_predict_from_tasks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/t5/evaluation/eval_utils.py\u001b[0m in \u001b[0;36mrun_eval\u001b[0;34m(mixture_or_task_name, predict_or_score_fn, checkpoint_steps, dataset_fn, summary_dir, split, sequence_length, batch_size)\u001b[0m\n\u001b[1;32m    314\u001b[0m   \"\"\"\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m   \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixture_or_task_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m   tasks = t5.data.get_subtasks(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/t5/models/utils.py\u001b[0m in \u001b[0;36mget_vocabulary\u001b[0;34m(mixture_or_task_name)\u001b[0m\n\u001b[1;32m    112\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not extract mixture/task name from gin config.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmixture_or_task_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0mprovider\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mixture_or_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixture_or_task_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprovider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"inputs\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"targets\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/seqio/dataset_providers.py\u001b[0m in \u001b[0;36mget_mixture_or_task\u001b[0;34m(task_or_mixture_name)\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mTaskRegistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_or_mixture_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1419\u001b[0;31m     raise ValueError(\"No Task or Mixture found with name: %s\" %\n\u001b[0m\u001b[1;32m   1420\u001b[0m                      task_or_mixture_name)\n\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No Task or Mixture found with name: glue_cola_v002"
     ]
    }
   ],
   "source": [
    "# Evaluate the pre-trained checkpoint, before further fine-tuning\n",
    "model.eval(\n",
    "    \"glue_cola_v002\",\n",
    "    sequence_length={\"inputs\": 64, \"targets\": 4},\n",
    "    batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b35f1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval.__code__.co_varnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166559f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval.__defaults__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a1de868",
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "No Task or Mixture found with name: glue_cola_v002",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f6657d18e131>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run 1000 steps of fine-tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model.train(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmixture_or_task_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"glue_cola_v002\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msave_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/t5/models/hf_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, mixture_or_task_name, steps, save_steps, sequence_length, split, batch_size, optimizer, learning_rate_scheduler)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \"\"\"\n\u001b[1;32m    319\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixture_or_task_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mixture_or_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixture_or_task_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     ds = tokens_to_batches(ds, sequence_length, batch_size,\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/t5/models/hf_model.py\u001b[0m in \u001b[0;36m_get_dataset\u001b[0;34m(mixture_or_task_or_name, sequence_length, split, shuffle)\u001b[0m\n\u001b[1;32m    167\u001b[0m   \"\"\"\n\u001b[1;32m    168\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixture_or_task_or_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mixture_or_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixture_or_task_or_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixture_or_task_or_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/seqio/dataset_providers.py\u001b[0m in \u001b[0;36mget_mixture_or_task\u001b[0;34m(task_or_mixture_name)\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mTaskRegistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_or_mixture_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1419\u001b[0;31m     raise ValueError(\"No Task or Mixture found with name: %s\" %\n\u001b[0m\u001b[1;32m   1420\u001b[0m                      task_or_mixture_name)\n\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No Task or Mixture found with name: glue_cola_v002"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run 1000 steps of fine-tuning\n",
    "model.train(\n",
    "    mixture_or_task_name=\"glue_cola_v002\",\n",
    "    steps=1000,\n",
    "    save_steps=100,\n",
    "    sequence_length={\"inputs\": 64, \"targets\": 4},\n",
    "    split=\"train\",\n",
    "    batch_size=32,\n",
    "    optimizer=functools.partial(transformers.AdamW, lr=1e-4),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bdb468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate after fine-tuning\n",
    "model.eval(\n",
    "    \"glue_cola_v002\",\n",
    "    checkpoint_steps=\"all\",\n",
    "    sequence_length={\"inputs\": 64, \"targets\": 4},\n",
    "    batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe676c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some predictions\n",
    "inputs = [\n",
    "    \"cola sentence: This is a totally valid sentence.\",\n",
    "    \"cola sentence: A doggy detail was walking famously.\",\n",
    "]\n",
    "model.predict(\n",
    "    inputs,\n",
    "    sequence_length={\"inputs\": 32},\n",
    "    batch_size=2,\n",
    "    output_file=\"/tmp/hft5/example_predictions.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987abe3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f0d92d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26332210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d042ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d90d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}